{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnose Brain MRI Images\n",
    "\n",
    "## Pre-requisites\n",
    "Install [kagglehub](https://pypi.org/project/kagglehub/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Dataset\n",
    "### 1.1 Download Data and Generate Annotation Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbd0/miniforge3/envs/3321/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Download dataset and locate it in machine\n",
    "data_dirname = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
    "# print(data_dirname)\n",
    "train_dirname = os.path.join(data_dirname, 'Training')\n",
    "test_dirname = os.path.join(data_dirname, 'Testing')\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Get training files\n",
    "tr_gl_files = glob(os.path.join(train_dirname, classes[0], '*.jpg'))\n",
    "tr_me_files = glob(os.path.join(train_dirname, classes[1], '*.jpg'))\n",
    "tr_no_files = glob(os.path.join(train_dirname, classes[2], '*.jpg'))\n",
    "tr_pi_files = glob(os.path.join(train_dirname, classes[3], '*.jpg'))\n",
    "# print(len(tr_gl_files), len(tr_me_files), len(tr_no_files), len(tr_pi_files))\n",
    "train_files = tr_gl_files + tr_me_files + tr_no_files + tr_pi_files\n",
    "train_labels = [classes[0]] * len(tr_gl_files) + \\\n",
    "    [classes[1]] * len(tr_me_files) + \\\n",
    "    [classes[2]] * len(tr_no_files) + \\\n",
    "    [classes[-1]] * len(tr_pi_files)\n",
    "train_dict = {'path': train_files, 'label': train_labels}\n",
    "df_train = pd.DataFrame(train_dict)\n",
    "# print(df_train)\n",
    "df_train.to_csv('annotation_train.csv', header=False, index=False)\n",
    "\n",
    "# Get testing files\n",
    "te_gl_files = glob(os.path.join(test_dirname, classes[0], '*.jpg'))\n",
    "te_me_files = glob(os.path.join(test_dirname, classes[1], '*.jpg'))\n",
    "te_no_files = glob(os.path.join(test_dirname, classes[2], '*.jpg'))\n",
    "te_pi_files = glob(os.path.join(test_dirname, classes[3], '*.jpg'))\n",
    "# print(len(te_gl_files), len(te_me_files), len(te_no_files), len(te_pi_files))\n",
    "test_files = te_gl_files + te_me_files + te_no_files + te_pi_files\n",
    "test_labels = [classes[0]] * len(te_gl_files) + \\\n",
    "    [classes[1]] * len(te_me_files) + \\\n",
    "    [classes[2]] * len(te_no_files) + \\\n",
    "    [classes[-1]] * len(te_pi_files)\n",
    "test_dict = {'path': test_files, 'label': test_labels}\n",
    "df_test = pd.DataFrame(test_dict)\n",
    "# print(df_train)\n",
    "df_test.to_csv('annotation_test.csv', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbd0/miniforge3/envs/3321/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "# import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "classes = ('glioma', 'meningioma', 'notumor', 'pituitary')\n",
    "trans = v2.Compose(\n",
    "    [\n",
    "        v2.ToTensor(),\n",
    "        v2.Normalize((0.5,), (0.5,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, annotations_file, transform=None, target_transform=None):\n",
    "        self.imgs_info = pd.read_csv(annotations_file, header=None)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_info)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs_info.iloc[idx, 0]\n",
    "        image = read_image(img_path)\n",
    "        label = self.imgs_info.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "        # img_resize = cv.resize(img_raw, (128, 128))\n",
    "        # image = np.float32(img_resize / 255)\n",
    "        # if self.imgs_info.iloc[idx, 1] == classes[0]:\n",
    "        #     category = 0\n",
    "        # elif self.imgs_info.iloc[idx, 1] == classes[1]:\n",
    "        #     category = 1\n",
    "        # elif self.imgs_info.iloc[idx, 1] == classes[2]:\n",
    "        #     category = 2\n",
    "        # else:\n",
    "        #     category = 3\n",
    "        # sample = {'image': image, 'category': category}\n",
    "        # return sample\n",
    "    \n",
    "dataset_train = TumorDataset(annotations_file='annotation_train.csv')\n",
    "# for i, sample in enumerate(dataset_train):\n",
    "#     image = sample['image']\n",
    "#     label = sample['category']\n",
    "#     if not i%100:  # i % 100 != 0\n",
    "#         print(i, image.shape, label)\n",
    "# print(i, image.shape, label)\n",
    "# dataset_test = TumorDataset(annotations_file='annotation_test.csv')\n",
    "\n",
    "# dataloader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "# dataloader_test = DataLoader(dataset_test, batch_size=64, shuffle=True)\n",
    "\n",
    "# for i, sample_batch in enumerate(dataloader_train):\n",
    "#     print(f\"Shape of X [N, H, W]: {sample_batch['image'].shape}\")\n",
    "#     print(f\"Shape of y: {sample_batch['category'].shape}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(81, dtype=torch.uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0][0][0, 200, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3321",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
