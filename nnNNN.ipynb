{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Brain MRI Images (Multi-Class Classification)\n",
    "\n",
    "## Pre-requisites\n",
    "Install [kagglehub](https://pypi.org/project/kagglehub/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Download dataset and locate it in machine\n",
    "data_dirname = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
    "# print(data_dirname)\n",
    "train_dirname = os.path.join(data_dirname, 'Training')\n",
    "test_dirname = os.path.join(data_dirname, 'Testing')\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Get training files\n",
    "tr_gl_files = glob(os.path.join(train_dirname, classes[0], '*.jpg'))\n",
    "tr_me_files = glob(os.path.join(train_dirname, classes[1], '*.jpg'))\n",
    "tr_no_files = glob(os.path.join(train_dirname, classes[2], '*.jpg'))\n",
    "tr_pi_files = glob(os.path.join(train_dirname, classes[3], '*.jpg'))\n",
    "# print(len(tr_gl_files), len(tr_me_files), len(tr_no_files), len(tr_pi_files))\n",
    "train_files = tr_gl_files + tr_me_files + tr_no_files + tr_pi_files\n",
    "train_labels = [classes[0]] * len(tr_gl_files) + \\\n",
    "    [classes[1]] * len(tr_me_files) + \\\n",
    "    [classes[2]] * len(tr_no_files) + \\\n",
    "    [classes[-1]] * len(tr_pi_files)\n",
    "train_dict = {'path': train_files, 'label': train_labels}\n",
    "df_train = pd.DataFrame(train_dict)\n",
    "# print(df_train)\n",
    "df_train.to_csv('annotation_train.csv', header=False, index=False)\n",
    "\n",
    "# Get testing files\n",
    "te_gl_files = glob(os.path.join(test_dirname, classes[0], '*.jpg'))\n",
    "te_me_files = glob(os.path.join(test_dirname, classes[1], '*.jpg'))\n",
    "te_no_files = glob(os.path.join(test_dirname, classes[2], '*.jpg'))\n",
    "te_pi_files = glob(os.path.join(test_dirname, classes[3], '*.jpg'))\n",
    "# print(len(te_gl_files), len(te_me_files), len(te_no_files), len(te_pi_files))\n",
    "test_files = te_gl_files + te_me_files + te_no_files + te_pi_files\n",
    "test_labels = [classes[0]] * len(te_gl_files) + \\\n",
    "    [classes[1]] * len(te_me_files) + \\\n",
    "    [classes[2]] * len(te_no_files) + \\\n",
    "    [classes[-1]] * len(te_pi_files)\n",
    "test_dict = {'path': test_files, 'label': test_labels}\n",
    "df_test = pd.DataFrame(test_dict)\n",
    "# print(df_train)\n",
    "df_test.to_csv('annotation_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create customized dataset\n",
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, annotations_file):\n",
    "        self.imgs_info = pd.read_csv(annotations_file, header=None)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_path = self.imgs_info.iloc[idx, 0]\n",
    "        image_raw = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n",
    "        image = cv.resize(image_raw, (100, 100))\n",
    "        category = 1. if self.imgs_info.iloc[idx, 1] == 'dog' else 0.\n",
    "        sample = {'image': image, 'category': category}\n",
    "        return sample\n",
    "\n",
    "# Loop training dataset\n",
    "dataset_train = CatsDogsDataset(annotations_file='annotation_train.csv')\n",
    "for i, sample in enumerate(dataset_train):\n",
    "    image = sample['image']\n",
    "    category = sample['category']\n",
    "    if not i%100:\n",
    "        print(i, image.shape, category)\n",
    "print(i, image.shape, category)\n",
    "    \n",
    "dataset_test = CatsDogsDataset(annotations_file='annotation_test.csv')\n",
    "\n",
    "# Create shuffled data loader \n",
    "dataloader_train = DataLoader(dataset_train, batch_size=1000, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=1000, shuffle=True)\n",
    "samples = next(iter(dataloader_train))\n",
    "fig, axs = plt.subplots(1, 4)\n",
    "for i in range(4):\n",
    "    image = samples['image'][i]\n",
    "    category = samples['category'][i]\n",
    "    axs[i] = plt.subplot(1, 4, i + 1)\n",
    "    axs[i].set_title(f'Sample #{i+1}: {category}')\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(image)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3321",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
