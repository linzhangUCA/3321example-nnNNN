{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Brain MRI Images (Multi-Class Classification)\n",
    "\n",
    "## Pre-requisites\n",
    "Install [kagglehub](https://pypi.org/project/kagglehub/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 1,
>>>>>>> aec3dd4 (update to model)
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbd0/miniforge3/envs/3321/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Download dataset and locate it in machine\n",
    "data_dirname = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
    "# print(data_dirname)\n",
    "train_dirname = os.path.join(data_dirname, 'Training')\n",
    "test_dirname = os.path.join(data_dirname, 'Testing')\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Get training files\n",
    "tr_gl_files = glob(os.path.join(train_dirname, classes[0], '*.jpg'))\n",
    "tr_me_files = glob(os.path.join(train_dirname, classes[1], '*.jpg'))\n",
    "tr_no_files = glob(os.path.join(train_dirname, classes[2], '*.jpg'))\n",
    "tr_pi_files = glob(os.path.join(train_dirname, classes[3], '*.jpg'))\n",
    "# print(len(tr_gl_files), len(tr_me_files), len(tr_no_files), len(tr_pi_files))\n",
    "train_files = tr_gl_files + tr_me_files + tr_no_files + tr_pi_files\n",
    "train_labels = [classes[0]] * len(tr_gl_files) + \\\n",
    "    [classes[1]] * len(tr_me_files) + \\\n",
    "    [classes[2]] * len(tr_no_files) + \\\n",
    "    [classes[-1]] * len(tr_pi_files)\n",
    "train_dict = {'path': train_files, 'label': train_labels}\n",
    "df_train = pd.DataFrame(train_dict)\n",
    "# print(df_train)\n",
    "df_train.to_csv('annotation_train.csv', header=False, index=False)\n",
    "\n",
    "# Get testing files\n",
    "te_gl_files = glob(os.path.join(test_dirname, classes[0], '*.jpg'))\n",
    "te_me_files = glob(os.path.join(test_dirname, classes[1], '*.jpg'))\n",
    "te_no_files = glob(os.path.join(test_dirname, classes[2], '*.jpg'))\n",
    "te_pi_files = glob(os.path.join(test_dirname, classes[3], '*.jpg'))\n",
<<<<<<< HEAD
    "# print(len(te_gl_files), len(te_me_files), len(te_no_files), len(te_pi_files))\n",
=======
    "# print(len(tr_gl_files))\n",
>>>>>>> aec3dd4 (update to model)
    "test_files = te_gl_files + te_me_files + te_no_files + te_pi_files\n",
    "test_labels = [classes[0]] * len(te_gl_files) + \\\n",
    "    [classes[1]] * len(te_me_files) + \\\n",
    "    [classes[2]] * len(te_no_files) + \\\n",
    "    [classes[-1]] * len(te_pi_files)\n",
    "test_dict = {'path': test_files, 'label': test_labels}\n",
    "df_test = pd.DataFrame(test_dict)\n",
    "# print(df_train)\n",
<<<<<<< HEAD
    "df_test.to_csv('annotation_test.csv', header=False, index=False)"
=======
    "df_test.to_csv('annotation_test.csv', header=False, index=False)\n"
>>>>>>> aec3dd4 (update to model)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### 1.1 Create PyTorch Dataset"
=======
    "### Create PyTorch Dataset from the Annotation Files"
>>>>>>> aec3dd4 (update to model)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> aec3dd4 (update to model)
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
<<<<<<< HEAD
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create customized dataset\n",
=======
    "import cv2 as cv\n",
    "\n",
>>>>>>> aec3dd4 (update to model)
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, annotations_file):\n",
    "        self.imgs_info = pd.read_csv(annotations_file, header=None)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_info)\n",
<<<<<<< HEAD
    "\n",
=======
    "    \n",
>>>>>>> aec3dd4 (update to model)
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_path = self.imgs_info.iloc[idx, 0]\n",
<<<<<<< HEAD
    "        image_raw = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n",
    "        image = cv.resize(image_raw, (100, 100))\n",
    "        category = 1. if self.imgs_info.iloc[idx, 1] == 'dog' else 0.\n",
    "        sample = {'image': image, 'category': category}\n",
    "        return sample\n",
    "\n",
    "# Loop training dataset\n",
    "dataset_train = CatsDogsDataset(annotations_file='annotation_train.csv')\n",
    "for i, sample in enumerate(dataset_train):\n",
    "    image = sample['image']\n",
    "    category = sample['category']\n",
    "    if not i%100:\n",
    "        print(i, image.shape, category)\n",
    "print(i, image.shape, category)\n",
    "    \n",
    "dataset_test = CatsDogsDataset(annotations_file='annotation_test.csv')\n",
    "\n",
    "# Create shuffled data loader \n",
    "dataloader_train = DataLoader(dataset_train, batch_size=1000, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=1000, shuffle=True)\n",
    "samples = next(iter(dataloader_train))\n",
    "fig, axs = plt.subplots(1, 4)\n",
    "for i in range(4):\n",
    "    image = samples['image'][i]\n",
    "    category = samples['category'][i]\n",
    "    axs[i] = plt.subplot(1, 4, i + 1)\n",
    "    axs[i].set_title(f'Sample #{i+1}: {category}')\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(image)\n",
    "    plt.tight_layout()"
=======
    "        img_raw = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n",
    "        image = cv.resize(img_raw, (128, 128))\n",
    "        if self.imgs_info.iloc[idx, 1] == classes[0]:\n",
    "            category = 0\n",
    "        elif self.imgs_info.iloc[idx, 1] == classes[1]:\n",
    "            category = 1\n",
    "        elif self.imgs_info.iloc[idx, 1] == classes[2]:\n",
    "            category = 2\n",
    "        else:\n",
    "            category = 3\n",
    "        sample = {'image': image, 'category': category}\n",
    "        return sample\n",
    "    \n",
    "dataset_train = TumorDataset(annotations_file='annotation_train.csv')\n",
    "# for i, sample in enumerate(dataset_train):\n",
    "#     image = sample['image']\n",
    "#     label = sample['category']\n",
    "#     if not i%100:  # i % 100 != 0\n",
    "#         print(i, image.shape, label)\n",
    "# print(i, image.shape, label)\n",
    "dataset_test = TumorDataset(annotations_file='annotation_test.csv')\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=10000, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=10000, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5712, 128, 128) (5712,)\n",
      "(1311, 128, 128) (1311,)\n",
      "(5712, 16384) (5712, 1)\n",
      "(1311, 16384) (1311, 1)\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels from the dataloaders\n",
    "data_train = next(iter(dataloader_train))\n",
    "data_test = next(iter(dataloader_test))\n",
    "\n",
    "# Separate features and labels\n",
    "raw_features_train = data_train['image'].numpy()\n",
    "raw_features_test = data_test['image'].numpy()\n",
    "raw_labels_train = data_train['category'].numpy()\n",
    "raw_labels_test = data_test['category'].numpy()\n",
    "print(raw_features_train.shape, raw_labels_train.shape)\n",
    "print(raw_features_test.shape, raw_labels_test.shape)\n",
    "\n",
    "# Reshape\n",
    "reshaped_features_train = raw_features_train.reshape(raw_features_train.shape[0], -1)\n",
    "reshaped_features_test = raw_features_test.reshape(raw_features_test.shape[0], -1)\n",
    "reshaped_labels_train = raw_labels_train.reshape(raw_labels_train.shape[0], 1)\n",
    "reshaped_labels_test = raw_labels_test.reshape(-1, 1)\n",
    "print(reshaped_features_train.shape, reshaped_labels_train.shape)\n",
    "print(reshaped_features_test.shape, reshaped_labels_test.shape)\n",
    "\n",
    "# Rescale\n",
    "rescaled_features_train = reshaped_features_train / 255\n",
    "rescaled_features_test = reshaped_features_test / 255\n",
    "# print(rescaled_features_test[0, 8000:8500])\n",
    "\n",
    "features_train = rescaled_features_train\n",
    "features_test = rescaled_features_test\n",
    "labels_train = reshaped_labels_train\n",
    "labels_test = reshaped_labels_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Multi-Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[-3.84744336e-05],\n",
      "       [ 8.31769662e-05]]), 'b1': array([[ 1.64647264e-05, -9.18241269e-05]]), 'W2': array([[ 6.80479932e-05, -3.12111746e-05],\n",
      "       [-7.74802255e-05, -2.43256509e-05],\n",
      "       [ 2.00883415e-04,  1.50724970e-05]]), 'b2': array([[-8.73451947e-05, -2.40308656e-05,  3.40069905e-05]]), 'W3': array([[-3.63648482e-05, -9.99954621e-06, -1.11426623e-05],\n",
      "       [-6.84476190e-05,  7.98544787e-05, -1.94926137e-04],\n",
      "       [-1.34602485e-04,  1.33233611e-04, -4.43483452e-05],\n",
      "       [-1.85105241e-04,  1.12453665e-04, -1.14182557e-04]]), 'b3': array([[-2.18533937e-05, -3.28653727e-05,  1.33016520e-05,\n",
      "        -7.31441817e-05]]), 'W4': array([[ 3.60224765e-05, -3.64039448e-05, -2.61637336e-05,\n",
      "        -4.78079969e-05],\n",
      "       [ 7.89697652e-06,  8.78496778e-05,  1.65006166e-05,\n",
      "        -2.82880696e-05],\n",
      "       [ 2.93728623e-05,  1.01869167e-04, -6.52602797e-05,\n",
      "         8.94220728e-05],\n",
      "       [-1.94886609e-05, -3.11019521e-05,  2.24268023e-05,\n",
      "         5.98897029e-05],\n",
      "       [-4.54404045e-05, -3.76675417e-05,  8.29896570e-05,\n",
      "        -2.87879911e-05]]), 'b4': array([[ 4.08790636e-05, -2.38136380e-05,  6.67357770e-05,\n",
      "         5.87941894e-05,  3.99761873e-05]]), 'W5': array([[ 8.48875899e-05,  1.84037201e-05,  1.58324995e-04,\n",
      "         7.39023433e-05,  1.01954638e-05],\n",
      "       [ 9.85777184e-05, -1.55631908e-05, -2.36039576e-04,\n",
      "        -5.80901253e-05,  3.31284637e-06],\n",
      "       [-1.30888418e-04, -1.32329985e-04, -5.56271904e-05,\n",
      "         3.20200654e-05, -1.15611396e-04],\n",
      "       [ 7.77091113e-05,  1.24779268e-04, -3.34871267e-05,\n",
      "        -7.40971222e-05,  1.08846729e-04],\n",
      "       [-8.48369761e-05, -1.35287806e-04,  8.76699715e-05,\n",
      "        -1.33645383e-04, -7.38401041e-05],\n",
      "       [ 1.38520902e-04, -5.20915396e-05,  6.95614146e-05,\n",
      "        -1.66568368e-05, -3.67033283e-05]]), 'b5': array([[ 1.04259664e-04, -7.98667240e-06,  2.73308632e-04,\n",
      "        -2.09061937e-04, -2.70919145e-06, -1.24858765e-04]]), 'W6': array([[-8.03390222e-05,  9.41789538e-06, -2.95697531e-05,\n",
      "        -8.87669332e-05,  3.00418180e-05,  1.28689957e-04],\n",
      "       [ 4.82041602e-05, -6.85720097e-05,  1.44908647e-05,\n",
      "         6.53916093e-06, -1.41767105e-05, -4.73963712e-05],\n",
      "       [-2.79950687e-04,  1.80907215e-04,  9.18279476e-05,\n",
      "        -1.93638161e-04, -2.45584142e-04,  1.33946302e-04],\n",
      "       [ 2.98736327e-06,  1.65410139e-05, -1.45297638e-04,\n",
      "         6.63573376e-06, -6.24948997e-05, -4.56848553e-05],\n",
      "       [-1.69820157e-04, -9.37220573e-05,  1.57349137e-04,\n",
      "        -1.02043313e-04, -5.07926517e-05, -7.54436589e-05],\n",
      "       [-2.65886656e-05, -3.33756769e-05, -5.45320489e-05,\n",
      "        -7.26904498e-05,  2.61540458e-05,  1.61933923e-04],\n",
      "       [ 1.81317845e-04,  1.39476068e-04,  4.31824464e-05,\n",
      "        -2.63506600e-05, -2.88169624e-06, -5.57069573e-05]]), 'b6': array([[-6.47474770e-05,  2.36490945e-05,  7.80309928e-05,\n",
      "        -1.37326488e-04, -8.14708432e-05,  1.68062840e-04,\n",
      "        -9.38581264e-05]]), 'W7': array([[ 6.58545185e-05,  6.55320145e-05,  5.55615023e-05,\n",
      "        -9.47041881e-05,  1.99941021e-04,  2.24414562e-04,\n",
      "         8.01113068e-05],\n",
      "       [-1.14405926e-04, -1.38141194e-04,  1.21571156e-04,\n",
      "         9.14179559e-05, -1.53164349e-04, -8.05950186e-05,\n",
      "        -1.43917385e-04],\n",
      "       [ 1.23138951e-04, -1.02696049e-04, -2.01946686e-05,\n",
      "         2.20576283e-04,  8.35854800e-05,  1.21562493e-04,\n",
      "         1.04518255e-05],\n",
      "       [ 4.50767115e-05, -6.34830044e-05, -1.74352729e-05,\n",
      "         2.15551030e-05, -2.78771942e-05,  1.04627136e-05,\n",
      "        -1.71813750e-04],\n",
      "       [-4.31206601e-05, -1.89494845e-04,  4.76997162e-05,\n",
      "        -1.20969198e-04,  1.11089213e-04, -1.33041119e-04,\n",
      "        -8.91533911e-05],\n",
      "       [ 8.21196734e-05,  7.10260367e-05,  2.42647650e-04,\n",
      "        -2.49523705e-05, -1.38970123e-06, -4.25039199e-05,\n",
      "        -3.70843447e-05],\n",
      "       [ 6.82214112e-05, -5.16119763e-05, -6.72989637e-05,\n",
      "         1.22743588e-06, -2.10747644e-05,  9.36032774e-05,\n",
      "        -1.85076037e-04],\n",
      "       [ 4.39792953e-05, -1.14107715e-05, -5.39617709e-05,\n",
      "        -1.48305159e-05,  1.35883909e-04, -1.61761162e-04,\n",
      "         3.64488471e-05]]), 'b7': array([[ 1.22042707e-04,  1.32144708e-04, -8.39587793e-05,\n",
      "         6.58660282e-06, -1.84834050e-04,  9.70302697e-05,\n",
      "        -1.34168968e-05,  6.04041572e-05]]), 'W8': array([[-1.01778251e-05,  2.28945586e-04, -2.36711637e-04,\n",
      "        -7.41647958e-06, -9.40546392e-05, -6.23345538e-06,\n",
      "         6.56544436e-05, -9.00224879e-06],\n",
      "       [-9.74019822e-05, -1.94167396e-05, -3.20968891e-05,\n",
      "         4.96081289e-05,  1.33201451e-05,  1.97880176e-04,\n",
      "         1.25936466e-05,  1.44690821e-05],\n",
      "       [-1.03528599e-04,  1.22657185e-04, -6.92999365e-05,\n",
      "        -1.45431352e-05, -6.90163482e-05, -1.78624330e-04,\n",
      "         5.72685936e-06,  2.75837399e-05],\n",
      "       [-5.34256090e-05,  1.24134276e-04,  1.23375807e-04,\n",
      "         5.08000547e-05,  1.27050170e-05, -1.03860136e-04,\n",
      "        -5.05594614e-05, -7.73281131e-05],\n",
      "       [ 4.31941959e-05,  2.38246597e-05, -7.78589275e-05,\n",
      "        -1.09780253e-04, -6.19132945e-05, -1.00714080e-04,\n",
      "        -1.46218225e-04, -2.87268821e-04],\n",
      "       [ 6.68788434e-05, -1.00408665e-05, -1.28047455e-04,\n",
      "        -2.37224613e-05,  1.92010740e-05,  3.36479380e-05,\n",
      "         1.37594965e-06,  4.10335565e-05],\n",
      "       [-3.81589170e-05,  1.31580933e-06, -7.85615039e-05,\n",
      "        -1.99691990e-04,  7.80037626e-05,  9.73890684e-05,\n",
      "         1.10549757e-04,  2.27272990e-04],\n",
      "       [ 1.99410441e-05, -4.66180421e-05, -1.63055789e-04,\n",
      "         1.86806038e-05,  8.86714016e-05,  3.23567586e-05,\n",
      "         1.43873129e-04, -7.55436402e-05],\n",
      "       [ 2.53304874e-04, -1.07072319e-04,  1.25696056e-05,\n",
      "        -1.22456796e-04, -9.70414871e-05, -1.04085976e-04,\n",
      "         1.07156412e-04, -3.71782742e-05]]), 'b8': array([[-1.05167793e-04, -1.50800132e-04, -5.08211515e-05,\n",
      "        -4.96432100e-05,  4.59809578e-05, -2.26487955e-04,\n",
      "         1.08273579e-04,  2.39361983e-05, -9.95604571e-05]])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def init_params(layer_sizes):\n",
    "    \"\"\"\n",
    "    layer_sizes: list/tuple\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    for i in range(len(layer_sizes)-1):\n",
    "        parameters['W' + str(i+1)] = np.random.normal(0, 0.0001, size=(layer_sizes[i+1], layer_sizes[i]))\n",
    "        parameters['b' + str(i+1)] = np.random.normal(0, 0.0001, size=(1, layer_sizes[i+1]))\n",
    "    return parameters\n",
    "\n",
    "# Sanity check\n",
    "dummy_layer_sizes = list(range(1, 10))\n",
    "dummy_params = init_params(dummy_layer_sizes)\n",
    "print(dummy_params)\n",
    "\n",
    "def linear():\n",
    "    pass\n",
    "\n",
    "def activation():\n",
    "    pass\n",
    "\n",
    "def forward():\n",
    "    pass"
>>>>>>> aec3dd4 (update to model)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3321",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
